[ 2024-07-09 20:52:49,466  107 dagshub - INFO - Accessing as sanket-profile]
[ 2024-07-09 20:52:49,973  107 dagshub - INFO - Initialized MLflow to track repo "sanket-profile/recommendationSystem"]
[ 2024-07-09 20:52:49,974  107 dagshub - INFO - Repository sanket-profile/recommendationSystem initialized!]
[ 2024-07-09 20:52:50,006  21 COMPONENTS - INFO - Starting Data Ingestion]
[ 2024-07-09 20:52:51,044  25 COMPONENTS - INFO - Data Ingestion completed]
[ 2024-07-09 20:52:51,044  28 COMPONENTS - INFO - Text Cleaning and Preprocessing Started]
[ 2024-07-09 20:52:51,044  29 COMPONENTS - INFO - Removing all the NaN values from the title column]
[ 2024-07-09 20:52:51,268  35 COMPONENTS - INFO - Removed all NaN Values from title column]
[ 2024-07-09 20:52:51,268  36 COMPONENTS - INFO - Applying the function to concatenate two columns to form Single Title Description]
[ 2024-07-09 20:52:51,508  40 COMPONENTS - INFO - Function applied]
[ 2024-07-09 20:52:51,508  41 COMPONENTS - INFO - Removing duplicates]
[ 2024-07-09 20:52:51,525  45 COMPONENTS - INFO - Removed duplicates from titleDesc Column]
[ 2024-07-09 20:52:51,526  46 COMPONENTS - INFO - Dropping unnecessary Columns]
[ 2024-07-09 20:52:51,534  50 COMPONENTS - INFO - Dropped unnecessary Columns. Remaining columns are : Index(['Unnamed: 0', 'title', 'average_rating', 'rating_number', 'description',
       'images', 'store', 'parent_asin', 'titleDesc'],
      dtype='object')]
[ 2024-07-09 20:52:51,534  51 COMPONENTS - INFO - Lowering the case of titleDescr column]
[ 2024-07-09 20:52:51,548  55 COMPONENTS - INFO - Lowered the case of titleDesc column]
[ 2024-07-09 20:52:51,548  56 COMPONENTS - INFO - Removing Punctuations from the titleDesc column]
[ 2024-07-09 20:52:51,695  60 COMPONENTS - INFO - Removed Punctuations from the titleDesc column]
[ 2024-07-09 20:52:51,695  61 COMPONENTS - INFO - Removing stopwords from the titleDescr column]
[ 2024-07-09 20:53:51,400  65 COMPONENTS - INFO - Removed stopwords from the titleDescr column, Example value looks like : genuine leather belt men single prong metal buckle brown 4648]
[ 2024-07-09 20:53:51,401  66 COMPONENTS - INFO - Spliting the titleDescr column into list and removing duplicate words]
[ 2024-07-09 20:53:51,638  70 COMPONENTS - INFO - Splited the titleDescr column into list and removed duplicate words]
[ 2024-07-09 20:53:51,638  71 COMPONENTS - INFO - Removing all the NaN values from the titleDescr column]
[ 2024-07-09 20:53:51,776  77 COMPONENTS - INFO - Removed all NaN Values from titleDescr column]
[ 2024-07-09 20:53:51,776  78 COMPONENTS - INFO - Text Cleaning and Preprocessing completed]
[ 2024-07-09 20:53:51,776  79 COMPONENTS - INFO - Saving the transformed df into Artifact Folder]
[ 2024-07-09 20:53:53,001  83 COMPONENTS - INFO - Saved the transformed df into Artifact Folder]
[ 2024-07-09 20:54:01,005  40 COMPONENTS - INFO - Starting the training process]
[ 2024-07-09 20:54:01,007  41 COMPONENTS - INFO - Initializing W2V model with 100 feature output]
[ 2024-07-09 20:54:01,042  448 gensim.utils - INFO - Word2Vec lifecycle event {'params': 'Word2Vec<vocab=0, vector_size=100, alpha=0.03>', 'datetime': '2024-07-09T20:54:01.008280', 'gensim': '4.3.2', 'python': '3.12.0 | packaged by Anaconda, Inc. | (main, Oct  2 2023, 12:22:05) [Clang 14.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'created'}]
[ 2024-07-09 20:54:01,042  53 COMPONENTS - INFO - Initialized W2V model]
[ 2024-07-09 20:54:01,042  54 COMPONENTS - INFO - Building Vocab Count]
[ 2024-07-09 20:54:01,043  582 gensim.models.word2vec - INFO - collecting all words and their counts]
[ 2024-07-09 20:54:01,043  565 gensim.models.word2vec - INFO - PROGRESS: at sentence #0, processed 0 words, keeping 0 word types]
[ 2024-07-09 20:54:01,071  565 gensim.models.word2vec - INFO - PROGRESS: at sentence #10000, processed 160956 words, keeping 23009 word types]
[ 2024-07-09 20:54:01,090  565 gensim.models.word2vec - INFO - PROGRESS: at sentence #20000, processed 317897 words, keeping 35861 word types]
[ 2024-07-09 20:54:01,108  565 gensim.models.word2vec - INFO - PROGRESS: at sentence #30000, processed 473395 words, keeping 46120 word types]
[ 2024-07-09 20:54:01,126  565 gensim.models.word2vec - INFO - PROGRESS: at sentence #40000, processed 630506 words, keeping 55382 word types]
[ 2024-07-09 20:54:01,144  565 gensim.models.word2vec - INFO - PROGRESS: at sentence #50000, processed 787077 words, keeping 63837 word types]
[ 2024-07-09 20:54:01,162  565 gensim.models.word2vec - INFO - PROGRESS: at sentence #60000, processed 945699 words, keeping 71772 word types]
[ 2024-07-09 20:54:01,181  565 gensim.models.word2vec - INFO - PROGRESS: at sentence #70000, processed 1102934 words, keeping 78867 word types]
[ 2024-07-09 20:54:01,197  588 gensim.models.word2vec - INFO - collected 85241 word types from a corpus of 1243939 raw words and 78890 sentences]
[ 2024-07-09 20:54:01,197  637 gensim.models.word2vec - INFO - Creating a fresh vocabulary]
[ 2024-07-09 20:54:01,309  448 gensim.utils - INFO - Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 85241 unique words (100.00% of original 85241, drops 0)', 'datetime': '2024-07-09T20:54:01.309941', 'gensim': '4.3.2', 'python': '3.12.0 | packaged by Anaconda, Inc. | (main, Oct  2 2023, 12:22:05) [Clang 14.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}]
[ 2024-07-09 20:54:01,310  448 gensim.utils - INFO - Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 1243939 word corpus (100.00% of original 1243939, drops 0)', 'datetime': '2024-07-09T20:54:01.310078', 'gensim': '4.3.2', 'python': '3.12.0 | packaged by Anaconda, Inc. | (main, Oct  2 2023, 12:22:05) [Clang 14.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}]
[ 2024-07-09 20:54:01,462  745 gensim.models.word2vec - INFO - deleting the raw counts dictionary of 85241 items]
[ 2024-07-09 20:54:01,463  748 gensim.models.word2vec - INFO - sample=0.001 downsamples 38 most-common words]
[ 2024-07-09 20:54:01,463  448 gensim.utils - INFO - Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 1157525.6751127427 word corpus (93.1%% of prior 1243939)', 'datetime': '2024-07-09T20:54:01.463632', 'gensim': '4.3.2', 'python': '3.12.0 | packaged by Anaconda, Inc. | (main, Oct  2 2023, 12:22:05) [Clang 14.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'prepare_vocab'}]
[ 2024-07-09 20:54:01,766  805 gensim.models.word2vec - INFO - estimated required memory for 85241 words and 100 dimensions: 110813300 bytes]
[ 2024-07-09 20:54:01,766  863 gensim.models.word2vec - INFO - resetting layer weights]
[ 2024-07-09 20:54:01,795  448 gensim.utils - INFO - Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2024-07-09T20:54:01.795602', 'gensim': '4.3.2', 'python': '3.12.0 | packaged by Anaconda, Inc. | (main, Oct  2 2023, 12:22:05) [Clang 14.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'build_vocab'}]
[ 2024-07-09 20:54:01,795  59 COMPONENTS - INFO - Completed Building Vocab Count]
[ 2024-07-09 20:54:01,795  60 COMPONENTS - INFO - Starting training W2Vmodel]
[ 2024-07-09 20:54:01,795  448 gensim.utils - INFO - Word2Vec lifecycle event {'msg': 'training model with 8 workers on 85241 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=20 window=3 shrink_windows=True', 'datetime': '2024-07-09T20:54:01.795821', 'gensim': '4.3.2', 'python': '3.12.0 | packaged by Anaconda, Inc. | (main, Oct  2 2023, 12:22:05) [Clang 14.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}]
[ 2024-07-09 20:54:02,690  1652 gensim.models.word2vec - INFO - EPOCH 0: training on 1243939 raw words (1157598 effective words) took 0.9s, 1300202 effective words/s]
[ 2024-07-09 20:54:03,565  1652 gensim.models.word2vec - INFO - EPOCH 1: training on 1243939 raw words (1157467 effective words) took 0.9s, 1329182 effective words/s]
[ 2024-07-09 20:54:04,443  1652 gensim.models.word2vec - INFO - EPOCH 2: training on 1243939 raw words (1157485 effective words) took 0.9s, 1324371 effective words/s]
[ 2024-07-09 20:54:05,295  1652 gensim.models.word2vec - INFO - EPOCH 3: training on 1243939 raw words (1157584 effective words) took 0.8s, 1365219 effective words/s]
[ 2024-07-09 20:54:06,151  1652 gensim.models.word2vec - INFO - EPOCH 4: training on 1243939 raw words (1157396 effective words) took 0.9s, 1357820 effective words/s]
[ 2024-07-09 20:54:07,011  1652 gensim.models.word2vec - INFO - EPOCH 5: training on 1243939 raw words (1157554 effective words) took 0.9s, 1352612 effective words/s]
[ 2024-07-09 20:54:07,865  1652 gensim.models.word2vec - INFO - EPOCH 6: training on 1243939 raw words (1157353 effective words) took 0.8s, 1362543 effective words/s]
[ 2024-07-09 20:54:08,730  1652 gensim.models.word2vec - INFO - EPOCH 7: training on 1243939 raw words (1157470 effective words) took 0.9s, 1344216 effective words/s]
[ 2024-07-09 20:54:09,583  1652 gensim.models.word2vec - INFO - EPOCH 8: training on 1243939 raw words (1157793 effective words) took 0.8s, 1363138 effective words/s]
[ 2024-07-09 20:54:10,420  1652 gensim.models.word2vec - INFO - EPOCH 9: training on 1243939 raw words (1157537 effective words) took 0.8s, 1389812 effective words/s]
[ 2024-07-09 20:54:11,284  1652 gensim.models.word2vec - INFO - EPOCH 10: training on 1243939 raw words (1157458 effective words) took 0.9s, 1344784 effective words/s]
[ 2024-07-09 20:54:12,120  1652 gensim.models.word2vec - INFO - EPOCH 11: training on 1243939 raw words (1157556 effective words) took 0.8s, 1391096 effective words/s]
[ 2024-07-09 20:54:12,953  1652 gensim.models.word2vec - INFO - EPOCH 12: training on 1243939 raw words (1157255 effective words) took 0.8s, 1396237 effective words/s]
[ 2024-07-09 20:54:13,778  1652 gensim.models.word2vec - INFO - EPOCH 13: training on 1243939 raw words (1157565 effective words) took 0.8s, 1408854 effective words/s]
[ 2024-07-09 20:54:14,615  1652 gensim.models.word2vec - INFO - EPOCH 14: training on 1243939 raw words (1157633 effective words) took 0.8s, 1389549 effective words/s]
[ 2024-07-09 20:54:15,448  1652 gensim.models.word2vec - INFO - EPOCH 15: training on 1243939 raw words (1157560 effective words) took 0.8s, 1397044 effective words/s]
[ 2024-07-09 20:54:16,298  1652 gensim.models.word2vec - INFO - EPOCH 16: training on 1243939 raw words (1157764 effective words) took 0.8s, 1367929 effective words/s]
[ 2024-07-09 20:54:17,126  1652 gensim.models.word2vec - INFO - EPOCH 17: training on 1243939 raw words (1157378 effective words) took 0.8s, 1403720 effective words/s]
[ 2024-07-09 20:54:17,983  1652 gensim.models.word2vec - INFO - EPOCH 18: training on 1243939 raw words (1157649 effective words) took 0.9s, 1358446 effective words/s]
[ 2024-07-09 20:54:18,810  1652 gensim.models.word2vec - INFO - EPOCH 19: training on 1243939 raw words (1157577 effective words) took 0.8s, 1405254 effective words/s]
[ 2024-07-09 20:54:19,644  1652 gensim.models.word2vec - INFO - EPOCH 20: training on 1243939 raw words (1157925 effective words) took 0.8s, 1394658 effective words/s]
[ 2024-07-09 20:54:20,481  1652 gensim.models.word2vec - INFO - EPOCH 21: training on 1243939 raw words (1157470 effective words) took 0.8s, 1389898 effective words/s]
[ 2024-07-09 20:54:21,351  1652 gensim.models.word2vec - INFO - EPOCH 22: training on 1243939 raw words (1157213 effective words) took 0.9s, 1336359 effective words/s]
[ 2024-07-09 20:54:22,203  1652 gensim.models.word2vec - INFO - EPOCH 23: training on 1243939 raw words (1157779 effective words) took 0.8s, 1364729 effective words/s]
[ 2024-07-09 20:54:23,038  1652 gensim.models.word2vec - INFO - EPOCH 24: training on 1243939 raw words (1157403 effective words) took 0.8s, 1392424 effective words/s]
[ 2024-07-09 20:54:23,870  1652 gensim.models.word2vec - INFO - EPOCH 25: training on 1243939 raw words (1157664 effective words) took 0.8s, 1398493 effective words/s]
[ 2024-07-09 20:54:24,693  1652 gensim.models.word2vec - INFO - EPOCH 26: training on 1243939 raw words (1157184 effective words) took 0.8s, 1412641 effective words/s]
[ 2024-07-09 20:54:25,559  1652 gensim.models.word2vec - INFO - EPOCH 27: training on 1243939 raw words (1157452 effective words) took 0.9s, 1341942 effective words/s]
[ 2024-07-09 20:54:26,387  1652 gensim.models.word2vec - INFO - EPOCH 28: training on 1243939 raw words (1157544 effective words) took 0.8s, 1405240 effective words/s]
[ 2024-07-09 20:54:27,249  1652 gensim.models.word2vec - INFO - EPOCH 29: training on 1243939 raw words (1157615 effective words) took 0.9s, 1348995 effective words/s]
[ 2024-07-09 20:54:27,249  448 gensim.utils - INFO - Word2Vec lifecycle event {'msg': 'training on 37318170 raw words (34725881 effective words) took 25.5s, 1364237 effective words/s', 'datetime': '2024-07-09T20:54:27.249907', 'gensim': '4.3.2', 'python': '3.12.0 | packaged by Anaconda, Inc. | (main, Oct  2 2023, 12:22:05) [Clang 14.0.6 ]', 'platform': 'macOS-14.2.1-arm64-arm-64bit', 'event': 'train'}]
[ 2024-07-09 20:54:27,249  64 COMPONENTS - INFO - Completed Training W2Vmodel]
[ 2024-07-09 20:54:27,250  65 COMPONENTS - INFO - Converting each word in titleDescr column(LIST) to feature representation]
[ 2024-07-09 20:54:27,865  69 COMPONENTS - INFO - Converted each word in titleDescr column(LIST) to feature representation]
[ 2024-07-09 20:54:27,866  70 COMPONENTS - INFO - Applying mean to titleDescr Colum to form a single sentence encoding]
[ 2024-07-09 20:54:28,523  74 COMPONENTS - INFO - Applied mean and formed the sentence embeddings]
[ 2024-07-09 20:54:28,523  75 COMPONENTS - INFO - Starting training of PCA model to conver 100 dimensions to 50 dimensions]
[ 2024-07-09 20:54:35,746  82 COMPONENTS - INFO - Trained the PCA model and saved the dimensionality reduced data]
[ 2024-07-09 20:54:35,747  83 COMPONENTS - INFO - Saving W2Vmodel and PCA model into pickle file in Artifact Folder]
[ 2024-07-09 20:54:35,893  88 COMPONENTS - INFO - Saved W2Vmodel and PCA model into pickle file]
[ 2024-07-09 20:54:35,893  89 COMPONENTS - INFO - Saving PCA data into Artifacts Folder]
[ 2024-07-09 20:54:35,905  93 COMPONENTS - INFO - Saved PCA data into Artifacts Folder]
